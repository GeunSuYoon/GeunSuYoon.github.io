---
layout: post
categories:
  - webservice
title: robot.txt
date: 2024-04-24 01:53:00 +09:00
tags:
---
# \[WEB] robot.txt

>simple explane

## H2 tag

### H3 tag (element about H2 tag)
- explane about H3 tag


## SEO를 높이는 요소

### robot.txt
- robot.txt는 크롤러가 사이트의 섹션에 엑세스 하지 못하도록 하는 규칙이 적힌 파일이다.
- 다르게 말하면 \"우리 사이트의 여기 저기를 확인해주세요!" 하는 가이드를 제공하는 역할을 한다.
- 아래는 [google for developers](https://developers.google.com/search/docs/crawling-indexing/robots/robots_txt?hl=ko)에서 제시한 example이다.

`# This robots.txt file controls crawling of URLs under https://example.com.`
`# All crawlers are disallowed to crawl files in the "includes" directory, such`
`# as .css, .js, but Google needs them for rendering, so Googlebot is allowed`
`# to crawl them.`
`User-agent: *`
`Disallow: /includes/`

`User-agent: Googlebot`
`Allow: /includes/`

`Sitemap: https://example.com/sitemap.xml`

- 